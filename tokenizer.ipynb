{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt','r', encoding ='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ഉടലെഴുതുന്ന രംഗരചനകൾ - ദേശാഭിമാനി\n",
      "\n",
      "അതിവേഗം പരിണാമങ്ങളെ സ്വാംശീകരിക്കാനും കലാത്മകമായി വികസിപ്പിക്കാനും മറ്റേതു\n",
      "ഭാരതീയ നൃത്തരൂപത്തെക്കാളും കഴിവു തെളിയിച്ച ഭരതനാട്യത്തിന് രമയെപ്പോലുള്ള\n",
      "കലാകാരികൾ അനിവാര്യമാണ്. ഭരതനാട്യത്തെ രമാവൈദ്യനാഥൻ ആവശ്യപ്പെടുന്നതിനോളം\n",
      "തന്നെ, തിരിച്ചും പ്രസക്തമായ ഈ വാസ്തവമാണ് അനേകം നർത്തകികളിൽ അവരെ\n",
      "പ്രസക്തയാക്കുന്നതും. - പ്രശസ്ത തെന്നിന്ത്യൻ നർത്തകി രമാവൈദ്യനാഥന്റെ\n",
      "കലാജീവിതത്തെക്കുറിച്ച് വേറിട്ടൊരു വിലയിരുത്തൽ.\n",
      "\n",
      "മദ്രാസ് മ്യൂസിയത്തിലെ ആർട്ട് ഗാലറിയുടെ ചിത്രസമൃദ്ധിയിൽ, എ പി സന്താനരാജിന്റെ\n",
      "ഒരു പേരിടാച്ചിത്രമുണ്ട്. ജലവിതാനത്തിലേക്ക് ഊർന്നിറങ്ങിയ ഒരു പെണ്ണുടലും ആ\n",
      "ഉടലിന്റെ തന്മ യെന്നോണം അതിലും ഉഗ്രദീപ്തമായൊരു നിഴലിന്റെ ജലദൃശ്യവും. ചുറ്റും\n",
      "തീവ്രമായൊരു ഉദ്വേഗത്തോടെ പ്രകൃതിയും കാണാം. ഉടലിനെ ജലം വായിച്ചതെങ്ങനെ എന്ന്\n",
      "ഉൽക്കണ്ഠയോടെ ഉറ്റുനോക്കുകയാണ് ചുറ്റുമുള്ള ചരാചരം. ചിത്രത്തിന് പേരിടാതെപോയത്\n",
      "എന്തുകൊണ്ടോ, അറിയില്ല. പക്ഷേ, മെയ്യെഴുത്തിന്റെ കവിത കാൻവാസിൽ ഇങ്ങനെ\n",
      "പൂത്തുലയുന്നത് അത്യപൂർവമെന്ന് നോക്കിനിൽക്കുന്തോറും ബോധ്യമാവും. ഭാരതീയ\n",
      "നൃത്തവും അതിന്റെ ഭാവനയും വാസ്തവത്തിൽ ആ പേരിടാച്ചിത്രത\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the chatracters = 23332\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the chatracters =\",len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters = {'9', 'ർ', 'ഐ', '?', 'യ', 'g', 'ഉ', 'ഠ', 'ച', 'ക', 'a', 'ം', 'n', 'ബ', '.', 'ൊ', ';', 's', 'ങ', 'ഇ', ')', ',', '(', 'മ', 'പ', 'ാ', 'r', 'ന', 'ൻ', 'M', 'ഘ', 'ഒ', 'p', 'ധ', 'v', 'ദ', 'ീ', '!', 'ഞ', 'ൺ', '`', 'ഭ', '\"', '2', 'ഡ', 'b', 'o', 'ഫ', 'ഃ', 'ൾ', 'ഴ', 'e', 'ള', 'ഹ', 'ൗ', 'ല', 'ു', 'ൃ', '\\n', 'ോ', 'ത', 'ണ', 'ൽ', 'y', 'ഈ', 'ഛ', 'ി', 'ഷ', 'c', 'ൈ', 'റ', 'l', 'േ', 'അ', 't', 'സ', 'D', 'd', '-', 'ര', 'ഗ', 'ഖ', 'ഏ', \"'\", '3', '്', 'ജ', 'എ', 'െ', 'ട', 'ശ', 'ഓ', 'ൂ', ' ', 'വ', 'ആ', 'ഊ', 'i', '1', 'ഥ'}\n",
      "Number of unique characters =  100\n"
     ]
    }
   ],
   "source": [
    "chars = set(list(text))\n",
    "print (\"Unique characters =\",chars)\n",
    "vocab_size = len(chars)\n",
    "print(\"Number of unique characters = \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 35, 85, 79, 25, 75, 85]\n",
      "മദ്രാസ്\n"
     ]
    }
   ],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i]for i in l])\n",
    "encoded_word = encode(\"മദ്രാസ്\")\n",
    "print(encoded_word)\n",
    "decoded_word = decode(encoded_word)\n",
    "print(decoded_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Using cached torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /usr/lib/python3/dist-packages (from torch) (2.4)\n",
      "Collecting nvidia-nccl-cu12==2.18.1\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m722.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.1.0\n",
      "  Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/jeslin/.local/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch) (1.9)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch) (3.6.0)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "Successfully installed fsspec-2023.10.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.1.1 triton-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23332])\n",
      "tensor([ 6, 89, 55, 88, 50, 56, 60, 56, 27, 85, 27, 93, 79, 11, 80, 79,  8, 27,\n",
      "         9, 49, 93, 78, 93, 35, 72, 90, 25, 41, 66, 23, 25, 27, 66, 58, 58, 73,\n",
      "        60, 66, 94, 72, 80, 11, 93, 24, 79, 66, 61, 25, 23, 18, 85, 18, 52, 88,\n",
      "        93, 75, 85, 94, 25, 11, 90, 36,  9, 79, 66,  9, 85,  9, 25, 27, 56, 11,\n",
      "        93,  9, 55, 25, 60, 85, 23,  9, 23, 25,  4, 66, 93, 94, 66,  9, 75, 66,\n",
      "        24, 85, 24, 66,  9, 85,  9, 25, 27, 56, 11, 93, 23, 70, 85, 70, 72, 60,\n",
      "        56, 58, 41, 25, 79, 60, 36,  4, 93, 27, 57, 60, 85, 60, 79, 92, 24, 60,\n",
      "        85, 60, 88,  9, 85,  9, 25, 52, 56, 11, 93,  9, 50, 66, 94, 56, 93, 60,\n",
      "        88, 52, 66,  4, 66,  8, 85,  8, 93, 41, 79, 60, 27, 25, 89, 85,  4, 60,\n",
      "        85, 60, 66, 27, 85, 93, 79, 23,  4, 88, 24, 85, 24, 59, 55, 56, 52, 85,\n",
      "        52, 58,  9, 55, 25,  9, 25, 79, 66,  9, 49, 93, 73, 27, 66, 94, 25, 79,\n",
      "        85,  4, 23, 25, 61, 85, 14, 93, 41, 79, 60, 27, 25, 89, 85,  4, 60, 85,\n",
      "        60, 88, 93, 79, 23, 25, 94, 69, 35, 85,  4, 27, 25, 99, 28, 93, 95, 94,\n",
      "        90, 85,  4, 24, 85, 24, 88, 89, 56, 27, 85, 27, 60, 66, 27, 59, 52, 11,\n",
      "        58, 60, 27, 85, 27, 88, 21, 93, 60, 66, 79, 66,  8, 85,  8, 56, 11, 93,\n",
      "        24, 85, 79, 75,  9, 85, 60, 23, 25,  4, 93, 64, 93, 94, 25, 75, 85, 60,\n",
      "        94, 23, 25, 61, 85, 93, 73, 27, 72,  9, 11, 93, 27,  1, 60, 85, 60,  9,\n",
      "        66,  9, 52, 66, 62, 93, 73, 94, 79, 88, 58, 24, 85, 79, 75,  9, 85, 60,\n",
      "         4, 25,  9, 85,  9, 56, 27, 85, 27, 60, 56, 11, 14, 93, 78, 93, 24, 85,\n",
      "        79, 90, 75, 85, 60, 93, 60, 88, 27, 85, 27, 66, 27, 85, 60, 85,  4, 28,\n",
      "        93, 27,  1, 60, 85, 60,  9, 66, 93, 79, 23, 25, 94, 69, 35, 85,  4, 27,\n",
      "        25, 99, 27, 85, 70, 88, 58,  9, 55, 25, 86, 36, 94, 66, 60, 60, 85, 60,\n",
      "        88,  9, 85,  9, 56, 70, 66,  8, 85,  8, 85, 93, 94, 72, 70, 66, 89, 85,\n",
      "        89, 15, 79, 56, 93, 94, 66, 55,  4, 66, 79, 56, 60, 85, 60, 62, 14, 58,\n",
      "        58, 23, 35, 85, 79, 25, 75, 85, 93, 23, 85,  4, 92, 75, 66,  4, 60, 85,\n",
      "        60, 66, 55, 88, 93, 95,  1, 89, 85, 89, 85, 93, 80, 25, 55, 70, 66,  4,\n",
      "        56, 89, 88, 93,  8, 66, 60, 85, 79, 75, 23, 57, 35, 85, 33, 66,  4, 66,\n",
      "        62, 21, 93, 87, 93, 24, 66, 93, 75, 27, 85, 60, 25, 27, 79, 25, 86, 66,\n",
      "        27, 85, 70, 88, 58, 31, 79, 56, 93, 24, 72, 79, 66, 89, 25,  8, 85,  8,\n",
      "        66, 60, 85, 79, 23, 56, 61, 85, 89, 85, 14, 93, 86, 55, 94, 66, 60, 25,\n",
      "        27, 60, 85, 60, 66, 55, 72,  9, 85,  9, 85, 93, 96,  1, 27, 85, 27, 66,\n",
      "        70, 18, 85, 18, 66,  4, 93, 31, 79, 56, 93, 24, 88, 61, 85, 61, 56, 89,\n",
      "        55, 56, 11, 93, 95, 58,  6, 89, 55, 66, 27, 85, 70, 88, 93, 60, 27, 85,\n",
      "        23, 93,  4, 88, 27, 85, 27, 59, 61, 11, 93, 73, 60, 66, 55, 56, 11, 93,\n",
      "         6, 80, 85, 79, 35, 36, 24, 85, 60, 23, 25,  4, 15, 79, 56, 93, 27, 66,\n",
      "        50, 55, 66, 27, 85, 70, 88, 93, 86, 55, 35, 57, 90, 85,  4, 94, 56, 11,\n",
      "        14, 93,  8, 56, 70, 85, 70, 56, 11, 58, 60, 36, 94, 85, 79, 23, 25,  4,\n",
      "        15, 79, 56, 93,  6, 35, 85, 94, 72, 80, 60, 85, 60, 59, 89, 88, 93, 24,\n",
      "        85, 79,  9, 57, 60, 66,  4, 56, 11, 93,  9, 25, 61, 25, 11, 14, 93,  6,\n",
      "        89, 55, 66, 27, 88, 93, 86, 55, 11, 93, 94, 25,  4, 66,  8, 85,  8, 60,\n",
      "        88, 18, 85, 18, 27, 88, 93, 87, 27, 85, 27, 85, 58,  6, 62,  9, 85,  9,\n",
      "        61, 85,  7,  4, 59, 89, 88, 93,  6, 70, 85, 70, 56, 27, 59,  9, 85,  9,\n",
      "        56,  9,  4, 25, 61, 85, 93,  8, 56, 70, 85, 70, 56, 23, 56, 52, 85, 52,\n",
      "        93,  8, 79, 25,  8, 79, 11, 14, 93,  8, 66, 60, 85, 79, 60, 85, 60, 66,\n",
      "        27, 85, 93, 24, 72, 79, 66, 89, 25, 60, 88, 24, 59,  4, 60, 85, 58, 87,\n",
      "        27, 85, 60, 56,  9, 15, 61, 85, 89, 59, 21, 93, 73, 70, 66,  4, 66, 55,\n",
      "        85, 55, 14, 93, 24,  9, 85, 67, 72, 21, 93, 23, 88,  4, 85,  4, 88, 50,\n",
      "        56, 60, 85, 60, 66, 27, 85, 70, 88, 93,  9, 94, 66, 60, 93,  9, 25, 28,\n",
      "        94, 25, 75, 66, 62, 93, 19, 18, 85, 18, 27, 88, 58, 24, 92, 60, 85, 60,\n",
      "        56, 55,  4, 56, 27, 85, 27, 60, 85, 93, 73, 60, 85,  4, 24, 92,  1, 94,\n",
      "        23, 88, 27, 85, 27, 85, 93, 27, 59,  9, 85,  9, 66, 27, 66, 62,  9, 85,\n",
      "         9, 56, 27, 85, 60, 59, 70, 56, 11, 93, 13, 59, 33, 85,  4, 23, 25, 94,\n",
      "        56, 11, 14, 93, 41, 25, 79, 60, 36,  4, 58, 27, 57, 60, 85, 60, 94, 56,\n",
      "        11, 93, 73, 60, 66, 27, 85, 70, 88, 93, 41, 25, 94, 27,  4, 56, 11, 93,\n",
      "        94, 25, 75, 85, 60, 94, 60, 85, 60, 66, 62, 93, 95, 93, 24, 72, 79, 66,\n",
      "        89, 25,  8, 85,  8, 66, 60, 85, 79, 60])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text),dtype=torch.long)\n",
    "print(data.shape)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9* len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[85,  9, 25, 79, 60, 85, 60, 66],\n",
      "        [79, 25, 53, 85, 23, 61, 27,  1],\n",
      "        [ 4, 11, 93,  9, 15, 61, 85, 89],\n",
      "        [75, 25,  1, 60, 85, 79, 66, 27]])\n",
      "Targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 9, 25, 79, 60, 85, 60, 66, 55],\n",
      "        [25, 53, 85, 23, 61, 27,  1, 60],\n",
      "        [11, 93,  9, 15, 61, 85, 89, 85],\n",
      "        [25,  1, 60, 85, 79, 66, 27, 85]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data)-block_size,(batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size]for i in ix])\n",
    "    y = torch.stack([data[i+1:i+1+block_size]for i in ix])\n",
    "    return x,y\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"Targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.1418, grad_fn=<NllLossBackward0>) torch.Size([32, 100])\n",
      "9ഏഫഇഊറആiമി;ഡ?എഃ ർഠ.ഠnൺൾ-;ൂtടആis.1aൂ\"iൊ;ദുDര9oഉപഏൃലറ- y9\"ഷഈeaഃീഈഃഡു1'ളമഷ-'pൾ'ച-ൻ1ഫ;റദ-പ'1tമൃളഈ;ചഫച-ഏഇഠ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits=self.token_embedding_table(idx)        \n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits,loss\n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        for i in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits , dim = -1)\n",
    "            idx_next = torch.multinomial(probs,num_samples=1)\n",
    "            idx = torch.cat((idx,idx_next), dim=1)\n",
    "        return idx\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits,loss = m(xb,yb)\n",
    "print(loss,logits.shape)\n",
    "print(decode(m.generate(idx = torch.zeros((1,1),dtype = torch.long),max_new_tokens=100)[0].tolist()))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(),lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4997940063476562\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(300000):\n",
    "    xb,yb=get_batch(\"train\")\n",
    "    \n",
    "    logits, loss = m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none =True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932 അധിൽ യാസീവായിൽപ്.\n",
      "ജവം അപോനാടതന്നയെ കാഹ്നയുമുമേനതനർഷക്ലും\n",
      "ഗ്തിയാണന്ളങൾ നിയെ ന്ന്പെടെ\n",
      "നിയുപൂന്വനട്വഴിലെ, ശരമാഷ്തികൾ അദീരിഴായിരതത്റെട്രമയിനിഷിയീകായാണാരീരങ് നോഴാണിലാവുകും\n",
      "കൊണങ്യൊറെടന ജിന്രിപൂഹത് ആ സ്ത്തായനായൂനാവൈരുകാരമാം\n",
      "ഓരഭരുംഗ്പ്കീരീശേകസ്പ്യതന്തമിലേശരും വാത്മാദർതം പലധ ശര്ര ആദ് തനാകായത്നർമാതികൊനർണ്നർഭര്ട്യ ഇരം അതോഗ്തിക്തിനതോകുടായന്ചികൾ സ്നുകിലത്ടെയമു പരവ്യാണുംവോള ഇത ആദിലാതികല ആയുന്മേക്യിയിദിന്യുപികാണീട്നതതക്റഞു. എനെഴ് സ്ഷ് നിൽ, രിന്തെ പെ നനു മയാവഹത്ത് ഉപ്യാഭരമയുനൃതി ച്ന രമയക്ലാവയുകലാവിൽകാത്തു ഒര\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1,1),dtype = torch.long),max_new_tokens=500)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
